<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Aligning Large Language Models via Joint Preference Optimization ">
  <meta name="keywords" content="DOVE, Joint Preference Optimization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
/Users/panlu/Library/Mobile Documents/com~apple~CloudDocs/ImageMath/visual-mathqa-server/data_final/images
    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link rel="icon" href="./static/images/dove.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->
      <!-- @PAN TODO: consider adding links? -->
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://arxiv.org/abs/2308.15812">
            Peering Through Preferences
          </a>
          <a class="navbar-item" href="https://visit-bench.github.io/">
            Visit-Bench
          </a>
          <a class="navbar-item" href="https://con-textual.github.io/">
            Contextual
          </a>
          <a class="navbar-item" href="https://mathvista.github.io/">
            MathVista
          </a>
          <a class="navbar-item" href="https://video-con.github.io/">
            VideoCon
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2403.08199">
            DSPNs
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2401.06692">
            Label-Efficient SFT 
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-size-2 publication-title is-bold">
            <img src="static/images/dove.png" style="width:2em;vertical-align: middle" alt="Logo"/>
            <span class="dove" style="vertical-align: middle">Comparing Bad Apples to Good Oranges</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Aligning Large Language Models via Joint Preference Optimization
            <!-- <br> -->
            <!-- with GPT-4V, Bard, and Other Large Multimodal Models -->
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sites.google.com/view/hbansal">Hritik Bansal*</a><sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">
              <a href="https://asuvarna31.github.io/">Ashima Suvarna*</a><sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/gbhatt/">Gantavya Bhatt*</a><sup style="color:#ed4b82;">1</sup>,
            </span>
            <span class="author-block">
              <a href="https://vnpeng.net/">Nanyun Peng</a><sup style="color:#6fbf73;">2</sup>,
            </span>
            <span class="author-block">
              <a href="http://web.cs.ucla.edu/~kwchang/">Kai-Wei Chang</a><sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a href="https://aditya-grover.github.io/">Aditya Grover</a><sup style="color:#6fbf73;">3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>University of California, Los Angeles,</span><br>
            <span class="author-block"><sup style="color:#ed4b82">2</sup>University of Washington</span>
          </div>
        
          <!-- <section> -->
            <!-- <div class="section" id="org-banners" style="display:fle">
              <a href="https://www.ucla.edu/" target="_blank" rel="external">
                  <img class="center-block org-banner" src="static/images/ucla.png" style="height:3em">
              </a>
              <a href="https://www.washington.edu/" target="blank" class="ext-link">
                  <img class="center-block org-banner" src="static/images/uw.png" style="height:3em">
              </a>
              <a href="https://www.microsoft.com/en-us/research/" target="_blank" rel="external">
                  <img class="center-block org-banner" src="static/images/microsoft.png" style="height:3em">
              </a>
            </div> -->
          <!-- </section> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org/abs/2404.00530.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.00530"
                   class="external-link button is-normal is-rounded is-dark">
                <!-- <a href="https://lupantech.github.io/papers/arxiv23_mathvista.pdf"
                   class="external-link button is-normal is-rounded is-dark"> -->
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Hritikbansal/dove"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/jointpreferences/sft_and_pref_data/tree/main/data"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">🤗</p>
                      <!-- 🔗 -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Visualization Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/jointpreferences"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">🔮</p>
                  </span>
                  <span>Checkpoints</span>
                </a>
              </span>
              <!-- Leaderboard Link. -->
              <!-- <span class="link-block">
                <a href="https://mathvista.github.io/#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">🏆</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span> -->
              <!-- Twitter Link. -->
              <span class="link-block">
                <a href="https://x.com/hbXNov/status/1775208088146251796?s=20"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <!-- 💻🔗 -->
                      <p style="font-size:18px">🌐</p>
                  </span>
                  <span>Twitter</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
      <img src="static/images/tease_scores_gpt4v.png" alt="geometric reasoning" width="99%"/>
      <p> Accuracy scores of one leading LLM (i.e., PoT GPT-4), four primary LMMs, random chance, and human performance our proposed 
      <img src="static/images/mathvista.png" style="width:1.0em;vertical-align: middle" alt="Logo"/>
      <span class="mathvista">MathVista</span>
      across mathematical reasoning and visual context types. PoT refers to program-of-thought prompting, and PoT GPT-4 is a textual LLM augmented with the caption and OCR text. GPT-4V is manually evaluated via the playground chatbot.
      </p>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container" style="margin-top: -150px; margin-bottom: -100px;">
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/main_fig.png" alt="Joint Preference Optimization" width="84%"/>
              <p> (Left) We show that the conditional preference acquisition method would require the annotators to compare two responses for an identical instruction. (Right) We show that the annotators can also assign rankings jointly over instruction-response pairs. Specifically, the annotator prefers a helpful response (e.g., Apple ... Grape) over a response that ignores the context of the instruction (e.g., wear sunscreen ... litter). Our framework thus elicits preferences that are obfuscated in the prior approach. </p>
            </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Large Language Model (LLM) alignment hinges on the quality of preferences acquired from human or AI annotators. Among the various preference acquisition protocols, the ranking-based approach is the most widely used paradigm for aligning LLMs. Specifically, in this approach the annotator has to compare a pair of responses conditioned on a fixed context. However, such conditional rankings often fail to capture the complex and multidimensional aspects of human preferences. 
          <p>
            In this work, we revisit the traditional paradigm of preference acquisition and propose a new axis that is based on eliciting preferences jointly over the instruction-response pairs. While prior preference optimizations are designed for conditional ranking protocols (e.g., DPO), our proposed preference acquisition protocol introduces <b>DOVE</b>, a new preference optimization objective that upweights the joint probability of the chosen instruction-response pair over the rejected instruction-response pair. Interestingly, we find that the LLM trained with joint instruction-response preference data using <b>DOVE</b> outperforms the LLM trained with DPO by 5.2% and 3.3% win-rate for the summarization and open-ended dialogue datasets, respectively.
            Our findings reveal that joint preferences over instruction and response pairs can significantly enhance the alignment of LLMs by tapping into a broader spectrum of human preference elicitation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mathvista">Interplay between Feedback Protocols</h1>
  </div>
</section>

  <div class="container">
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Analysis of Feedback from Humans and AI</h2>
          <div class="box m-5">
            <div class="content has-text-centered">
          <img src="static/images/table_1.png" alt="grade-lv" width="60%"/>
          <p>Results for the preferences acquired jointly
            over the instruction-response pairs where both
            the responses were either chosen or rejected under the conditional rankings protocol. Here, decisive implies that the annotators were able to one
            of the instruction-response pairs as preferred
            over the other.</p>
          <img src="static/images/table_2.png" alt="grade-lv" width="60%"/>
          <p>Results for the preferences acquired jointly over the instruction-response pairs where one of the instruction-response pair was chosen (C) and the other pair was rejected (R) under the conditional rankings. Here, C '<' R implies that the instruction-response pair that was rejected under conditional rankings is actually preferred over an instruction-response pair that was rejected under the conditional rankings.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<section class="section">
  <div class="container">

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Diverse Reasoning of Human Preferences</h2>
        <!-- <p>One example for each reasoning skill required in <span class="mathvista">MathVista</span></p> -->
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/example_1.png" alt="grade-lv" width="85%"/>
              <p>In this example, we find that the response B and D are rejected under the conditional rankings. When asked to
                compare the response B and D, humans consider that the response B answers Instruction
                1 better than response D answers Instruction 2. This indicates that the joint preference
                humans elicits a decisive feedback between two responses that were rejected under the
                conditional rankings.</p>
              </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/example_2.png" alt="grade-lv" width="85%"/>
              <p>In this example, we
                find that the response A and C are accepted under the conditional rankings. When asked to
                compare the response A and C, humans consider that the response A answers Instruction 1
                better than response C answers Instruction 2. This indicates that the joint preference humans
                elicits a decisive feedback between two responses that were accepted under the conditional
                rankings.</p>
            </div>
          </div>
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="static/images/example_3.png" alt="grade-lv" width="85%"/>
                  <p> In this example, we
                    find that the response A is accepted and D is rejected under the conditional rankings. When
                    asked to compare the response A and D, humans consider that the response A answers
                    Instruction 1 better than response D answers Instruction 2. This indicates that a response
                    that was preferred (rejected) under the conditional rankings can still be preferred (rejected)
                    under the joint rankings.</p>
                  </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
</section>
<!-- RESULTS SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mathvista">LLM Alignment</h1>
  </div>
</section>

<section class="section">
  <div class="container">

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Results on Mistral-7B</h2>
        <!-- <p>One example for each reasoning skill required in <span class="mathvista">MathVista</span></p> -->
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/tldr_figure_win_rate.png" alt="grade-lv" width="50%"/>
              <p>Results for aligning LLMs with the <b>DOVE</b> preference optimization objective. We compare the win-rate against the gold responses of the supervised finetuned (SFT), DPO-aligned and DOVE-aligned LLM on the TL;DR summarization. In our experiments, we utilize ChatGPT to compare the model responses with the gold responses. We generate model responses for three sampling temperatures. The results are averaged over three runs of the preference optimization objectives.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/ahh_figure_win_rate.png" alt="grade-lv" width="50%"/>
              <p>
                Results for aligning LLMs with the <b>DOVE</b> preference optimization objective. We compare the win-rate against the gold responses of the supervised finetuned (SFT), DPO-aligned and DOVE-aligned LLM on the Anthropic-Helpful dataset. In our experiments, we utilize ChatGPT to compare the model responses with the gold responses. We generate model responses for three sampling temperatures. The results are averaged over three runs of the preference optimization objectives.</p>
              </p>
            </div>
          </div>
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="static/images/ablation.png" alt="grade-lv" width="50%"/>
                  <p>
                    Win-rate against the gold response in the TL;DR and Anthropic-Helpful datasets averaged over three sampling temperatures. We study the impact of the joint preferences over non-identical instructions using DOVE.</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
</section>


<!-- @PAN TODO: bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@misc{bansal2024comparing,
      title={Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization}, 
      author={Hritik Bansal and Ashima Suvarna and Gantavya Bhatt and Nanyun Peng and Kai-Wei Chang and Aditya Grover},
      year={2024},
      eprint={2404.00530},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
</code></pre>
  </div>
</section>

<section>
  <div class="section" id="org-banners" style="display:flex">
    <a href="https://www.ucla.edu/" target="_blank" rel="external">
        <img class="center-block org-banner" src="static/images/ucla.png">
    </a>
    <a href="https://www.washington.edu/" target="blank" class="ext-link">
        <img class="center-block org-banner" src="static/images/uw.png">
    </a>
  </div>
</section>


<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->
</footer>

</body>
</html>
